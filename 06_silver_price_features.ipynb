{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab96e102-8ef6-40e5-bd1e-642c34f0ba0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "catalog_name = \"electricity-project\"\n",
    "silver_schema = \"silver\"\n",
    "\n",
    "input_table = \"silver.price_weather_joined\"\n",
    "output_table = \"silver.price_features\"\n",
    "\n",
    "LOOKBACK_HOURS = 48\n",
    "\n",
    "# =========================\n",
    "# CATALOG + SCHEMA\n",
    "# =========================\n",
    "spark.sql(f\"USE CATALOG `{catalog_name}`\")\n",
    "spark.sql(f\"USE SCHEMA {silver_schema}\")\n",
    "\n",
    "# =========================\n",
    "# DETERMINE WATERMARK\n",
    "# =========================\n",
    "if spark.catalog.tableExists(output_table):\n",
    "    max_dt = (\n",
    "        spark.table(output_table)\n",
    "        .agg(F.max(\"datetime\").alias(\"max_dt\"))\n",
    "        .collect()[0][\"max_dt\"]\n",
    "    )\n",
    "else:\n",
    "    max_dt = None\n",
    "\n",
    "# =========================\n",
    "# READ INPUT (INCREMENTAL)\n",
    "# =========================\n",
    "df = spark.table(input_table)\n",
    "\n",
    "if max_dt is not None:\n",
    "    df = df.filter(\n",
    "        F.col(\"datetime\") >= F.lit(max_dt) - F.expr(f\"INTERVAL {LOOKBACK_HOURS} HOURS\")\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# BASIC TIME FEATURES\n",
    "# =========================\n",
    "df = (\n",
    "    df\n",
    "    .withColumn(\"hour\", F.hour(\"datetime\"))\n",
    "    .withColumn(\"day_of_week\", F.dayofweek(\"datetime\") - 2)\n",
    ")\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"day_of_week\",\n",
    "    F.when(F.col(\"day_of_week\") == -1, 6)\n",
    "     .otherwise(F.col(\"day_of_week\"))\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# WINDOWS (SAFE PARTITIONING)\n",
    "# =========================\n",
    "trend_window = (\n",
    "    Window\n",
    "    .partitionBy(F.to_date(\"datetime\"))\n",
    "    .orderBy(\"datetime\")\n",
    ")\n",
    "\n",
    "lag_window = trend_window\n",
    "\n",
    "# =========================\n",
    "# TREND\n",
    "# =========================\n",
    "df = df.withColumn(\n",
    "    \"trend\",\n",
    "    F.row_number().over(trend_window) - 1\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# LAG FEATURES\n",
    "# =========================\n",
    "df = df.withColumn(\n",
    "    \"price_lag_24\",\n",
    "    F.lag(\"price_nok\", 24).over(lag_window)\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# ONE-HOT ENCODING (HOUR)\n",
    "# =========================\n",
    "for h in range(1, 24):\n",
    "    df = df.withColumn(\n",
    "        f\"hour_{h}\",\n",
    "        F.when(F.col(\"hour\") == h, 1).otherwise(0)\n",
    "    )\n",
    "\n",
    "df = df.drop(\"hour\")\n",
    "\n",
    "# =========================\n",
    "# ONE-HOT ENCODING (DAY OF WEEK)\n",
    "# =========================\n",
    "for d in range(1, 7):\n",
    "    df = df.withColumn(\n",
    "        f\"day_of_week_{d}\",\n",
    "        F.when(F.col(\"day_of_week\") == d, 1).otherwise(0)\n",
    "    )\n",
    "\n",
    "df = df.drop(\"day_of_week\")\n",
    "\n",
    "# =========================\n",
    "# FINAL COLUMN ORDER\n",
    "# =========================\n",
    "final_updates_df = df.select(\n",
    "    \"datetime\",\n",
    "    \"price_nok\",\n",
    "    \"temperature\",\n",
    "    \"trend\",\n",
    "    \"price_lag_24\",\n",
    "    *[f\"hour_{h}\" for h in range(1, 24)],\n",
    "    *[f\"day_of_week_{d}\" for d in range(1, 7)]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# MERGE INTO SILVER\n",
    "# =========================\n",
    "if spark.catalog.tableExists(output_table):\n",
    "\n",
    "    delta_out = DeltaTable.forName(spark, output_table)\n",
    "\n",
    "    (\n",
    "        delta_out.alias(\"t\")\n",
    "        .merge(\n",
    "            final_updates_df.alias(\"s\"),\n",
    "            \"t.datetime = s.datetime\"\n",
    "        )\n",
    "        .whenMatchedUpdateAll()\n",
    "        .whenNotMatchedInsertAll()\n",
    "        .execute()\n",
    "    )\n",
    "\n",
    "else:\n",
    "    (\n",
    "        final_updates_df\n",
    "        .write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .saveAsTable(output_table)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85afbdd7-ae02-4285-8c1b-9fd0cb32606e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM `electricity-project`.silver.price_features\n",
    "ORDER BY datetime\n",
    "LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5747a4a-457f-42c3-978b-cec3b94ea7e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM `electricity-project`.silver.price_features\n",
    "ORDER BY datetime DESC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dac26969-f4ee-46f7-9f0d-e0de15f6a4c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  count(*),\n",
    "  sum(CASE WHEN price_lag_24 IS NULL THEN 1 ELSE 0 END) AS lag_nulls\n",
    "FROM `electricity-project`.silver.price_features;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4749030902854967,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "06_silver_price_features",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
