{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5c4c8b4-c053-4f9d-bd1e-c42f02c20baa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "catalog_name = \"electricity-project\"\n",
    "gold_schema = \"gold\"\n",
    "\n",
    "input_table = \"gold.price_model_training_data\"\n",
    "output_table = \"gold.price_model_parameters\"\n",
    "\n",
    "# =========================\n",
    "# CATALOG + SCHEMA\n",
    "# =========================\n",
    "spark.sql(f\"USE CATALOG `{catalog_name}`\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {gold_schema}\")\n",
    "spark.sql(f\"USE SCHEMA {gold_schema}\")\n",
    "\n",
    "# =========================\n",
    "# MODEL VERSION (MONTHLY)\n",
    "# =========================\n",
    "current_version = (\n",
    "    spark.sql(\"SELECT date_format(current_date(), 'yyyyMM') AS v\")\n",
    "    .collect()[0][\"v\"]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# CHECK IF MODEL EXISTS\n",
    "# =========================\n",
    "if spark.catalog.tableExists(output_table):\n",
    "    exists = (\n",
    "        spark.table(output_table)\n",
    "        .filter(F.col(\"model_version\") == current_version)\n",
    "        .limit(1)\n",
    "        .count()\n",
    "    )\n",
    "    if exists > 0:\n",
    "        dbutils.notebook.exit(\n",
    "            f\"Model version {current_version} already exists. Skipping training.\"\n",
    "        )\n",
    "\n",
    "# =========================\n",
    "# READ TRAINING DATA\n",
    "# =========================\n",
    "df = spark.table(input_table)\n",
    "\n",
    "# =========================\n",
    "# DEFINE FEATURE COLUMNS\n",
    "# =========================\n",
    "feature_cols = (\n",
    "    [\"price_lag_24\", \"temperature\", \"trend\"]\n",
    "    + [c for c in df.columns if c.startswith(\"hour_\")]\n",
    "    + [c for c in df.columns if c.startswith(\"day_of_week_\")]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# DROP ROWS WITH MISSING FEATURES\n",
    "# =========================\n",
    "train_df = df.dropna(\n",
    "    subset=[\"price_nok\", \"price_lag_24\", \"temperature\"]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# VECTOR ASSEMBLER\n",
    "# =========================\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "train_vec = assembler.transform(train_df)\n",
    "\n",
    "# =========================\n",
    "# TRAIN LINEAR REGRESSION\n",
    "# =========================\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"price_nok\",\n",
    "    fitIntercept=True\n",
    ")\n",
    "\n",
    "model = lr.fit(train_vec)\n",
    "\n",
    "# =========================\n",
    "# EXTRACT COEFFICIENTS\n",
    "# =========================\n",
    "coef_rows = [\n",
    "    (name, float(coef))\n",
    "    for name, coef in zip(feature_cols, model.coefficients)\n",
    "]\n",
    "\n",
    "coef_df = spark.createDataFrame(\n",
    "    coef_rows,\n",
    "    [\"feature_name\", \"coefficient\"]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# MODEL METADATA\n",
    "# =========================\n",
    "stats = train_df.agg(\n",
    "    F.min(\"datetime\").alias(\"train_start\"),\n",
    "    F.max(\"datetime\").alias(\"train_end\"),\n",
    "    F.count(\"*\").alias(\"n_observations\")\n",
    ").collect()[0]\n",
    "\n",
    "final_df = (\n",
    "    coef_df\n",
    "    .withColumn(\"intercept\", F.lit(float(model.intercept)))\n",
    "    .withColumn(\"model_version\", F.lit(current_version))\n",
    "    .withColumn(\"trained_at\", F.current_timestamp())\n",
    "    .withColumn(\"train_start\", F.lit(stats[\"train_start\"]))\n",
    "    .withColumn(\"train_end\", F.lit(stats[\"train_end\"]))\n",
    "    .withColumn(\"n_observations\", F.lit(stats[\"n_observations\"]))\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# WRITE MODEL PARAMETERS\n",
    "# =========================\n",
    "(\n",
    "    final_df\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"append\")\n",
    "    .saveAsTable(output_table)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a27d5b25-15d2-4c31-823a-2bc7b4b7e86e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# SELECT *\n",
    "# FROM `electricity-project`.gold.day_ahead_price_forecast\n",
    "# ORDER BY datetime;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81dbfbbf-f553-435f-9e0f-6c2c87f6fc2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# SELECT\n",
    "#   avg(abs(actual_price - predicted_price)) AS mae\n",
    "# FROM `electricity-project`.gold.day_ahead_price_forecast;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4749030902854972,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "08_gold_model_train_monthly",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
